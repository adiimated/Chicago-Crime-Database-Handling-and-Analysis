# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11qJxRrRZGec0jWQzm1KQjo59QuqLTe6c
"""

import pandas as pd
import json

data_path = "Chicago_Crimes_2001_to_2004.csv"
df = pd.read_csv(data_path,  on_bad_lines='skip')
df.head(5)

df = df.dropna()

df.info()

df.head(0)

drop_cols_list = ['Unnamed: 0', 'Case Number', 'Beat']
df = df.drop(drop_cols_list, axis=1)
df.reset_index(drop=True, inplace=True)
df.info()

# Replace any spaces with underscores
df.columns = df.columns.str.replace(" ", "_")

# Make sure we strip any invisible white spaces
df.columns = df.columns.str.strip()

# Set all columns names to lower case
df.columns = df.columns.str.lower()

df.isnull().any()

for column in df.columns:
    print(column, " ::: ", type(df[column][0]))

#Normalizing data and changing the datatypes
#Inserting date as date doesn't work with sql so had to revert this change
#df["date"] = pd.to_datetime(df["date"], format = "%m/%d/%Y %I:%M:%S %p", utc = True)
#df["updated_on"] = pd.to_datetime(df["updated_on"], format = "%m/%d/%Y %I:%M:%S %p", utc = True)

pd.value_counts(df['location_description'])
len(df['location_description'].unique())

pd.value_counts(df['block'])
len(df['fbi_code'].unique())

df.head(3)

#Changing to categorical values.

#Not needed as of now.

#df['block'] = pd.factorize(df["block"])[0]
#df['description'] = pd.factorize(df["description"])[0]
#df['location_description'] = pd.factorize(df["location_description"])[0]
df['location'] = pd.factorize(df["location"])[0]

import numpy as np

#Converting float values to int

df["district"] = df["district"].astype(np.int64)
df["ward"] = df["ward"].astype(np.int64)
df["community_area"] = df["community_area"].astype(np.int64)
df["year"] = df["year"].astype(np.int64)

df.head(10)

for column in df.columns:
    print(column, " ::: ", type(df[column][0]))

import pandas as pd
import sqlite3
from sqlite3 import Error



def create_connection(db_file, delete_db=False):
    import os
    if delete_db and os.path.exists(db_file):
        os.remove(db_file)

    conn = None
    try:
        conn = sqlite3.connect(db_file)
        conn.execute("PRAGMA foreign_keys = 1")
    except Error as e:
        print(e)

    return conn


def create_table(conn, create_table_sql, drop_table_name=None):

    if drop_table_name: # You can optionally pass drop_table_name to drop the table.
        try:
            c = conn.cursor()
            c.execute("""DROP TABLE IF EXISTS %s""" % (drop_table_name))
        except Error as e:
            print(e)

    try:
        c = conn.cursor()
        c.execute(create_table_sql)
    except Error as e:
        print(e)



def execute_sql_statement(sql_statement, conn):
    cur = conn.cursor()
    cur.execute(sql_statement)

    rows = cur.fetchall()

    return rows

def create_crimes_table(processed_dataframe, normalized_database_filename):
    # Inputs: Name of the data and normalized database filename
    # Output: None

    ### BEGIN SOLUTION
    import pandas as pd
    conn = create_connection(normalized_database_filename,delete_db=False)
    with conn:
        create_crime_sql="""
    CREATE TABLE Crimes(
    id integer,
    date text,
    block text,
    iucr text,
    primary_type text,
    description text,
    location_description text,
    arrest Text,
    domestic Text,
    district integer,
    ward integer,
    community_area integer,
    fbi_code text,
    x_coordinate REAL,
    y_coordinate REAL,
    year integer,
    updated_on TEXT,
    latitude REAL,
    longitude REAL,
    location integer
    );"""
        create_table(conn, create_crime_sql, "Crimes")
        df = processed_dataframe

        cur = conn.cursor()
        #cur.executemany("INSERT INTO Region VALUES (?, ?)", rows)

create_crimes_table(df, "crimes.db")

def insert_crimes_table(processed_dataframe, normalized_database_filename):
    conn = create_connection(normalized_database_filename)
    list1 = list(zip(processed_dataframe.id, processed_dataframe.date, processed_dataframe.block, processed_dataframe.iucr, processed_dataframe.primary_type, processed_dataframe.description, processed_dataframe.location_description, processed_dataframe.arrest, processed_dataframe.domestic, processed_dataframe.district, processed_dataframe.ward, processed_dataframe.community_area, processed_dataframe.fbi_code, processed_dataframe.x_coordinate, processed_dataframe.y_coordinate, processed_dataframe.year, processed_dataframe.updated_on, processed_dataframe.latitude, processed_dataframe.longitude, processed_dataframe.location))
    with conn:
        insert_sql = """ insert into Crimes values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)"""
        cur = conn.cursor()

        cur.executemany(insert_sql, list1)
        conn.commit()

insert_crimes_table(df, "crimes.db")

conn = sqlite3.connect("crimes.db")
cur = conn.cursor()
sql_select = """select * from crimes where description like "PREDATORY" """
#desc = "PREDATORY"
select_df = pd.read_sql_query(sql_select, conn)
select_df